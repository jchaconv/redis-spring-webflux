Redis with Spring WebFlux

Repo de vinsguru: https://github.com/vinsguru/redis-webflux

Redis use cases:
-Caching
-Pub/Sub
-Message Queue
-Streaming
-GeoSpatial
...

*******************************
SECCIÓN 3: Redis - Crash Course
*******************************


docker-compose.yml

version: '3'
services:
  redis:
    container_name: redis
    hostname: redis
    image: redis:6.2
    ports:
    - 6379:6379

Ejecutar en un cmd ubicado en la dirección del archivo yml:

docker-compose up
docker exec -it redis bash
redis-cli
ping → retorna PONG

Para comandos de redis tener en cuenta la siguiente documentación:

https://redis.io/commands/
https://cheatography.com/tasjaevan/cheat-sheets/redis/


*******************************

#9. Storing Simple Key Values

set a b → OK
get a → "b"
get c → (nil)
set a 1 → "1" todo es representado como string

Es case sensitive

set user:1:name julio → OK
get user:1:name → "julio"

set somekey "some value" → para poder incluir espacios en blanco


*******************************


#10. Accessing All Keys

keys * → retorna todas las keys. No hacerlo si está integrado con aplicación
keys user* → sigue un patrón con la palabra user
scan 0 → muestra de 10 en 10 las keys y muestra al comienzo un número con el que se puede seguir navegando
scan 0 MATCH user* → para listar y seguir patrón
scan 6 MATCH user* count 3 → para listar solo 3 y no 10


*******************************

#11. Removing Keys

keys user*
del user:8:name → 1
del user:895:name → 0  nada que remover
del user:1:name user:2:name → 2  borrado múltiple

flushdb → remover todas las keys
keys * → (empty array)

El comando del no acepta un patrón, solo acepta keys.

*******************************


#12. Expiring Keys - Part 1

set a b ex 10 → expira en 10 secs
keys *
get a
get a → luego de 10 secs ya no aparece

set a b ex 10
ttl a → 5  muestra cuantos secs quedan para que expire

set a b ex 10
ttl a → 7
expire a 60 → establezco el tiempo de expiración a 60secs
ttl a → 58

expire a 600
expire a 50 → puedo reducir el tiempo de esta manera


*******************************


#13. Expiring Keys - Part 2

key *
set a b exat 1665619157 → para usar timestamp
ttl a → 204

set b c px 3000 → milisegundos
get b → "c"
get b → (nil)

set a b ex 600
ttl a → 580
set a c
ttl a → (integer) -1 ya está expirado porque se cambió el valor de la llave
flushdb

Para mantener el tiempo de expiración:

set a b ex 600
ttl a → 580
get a → "b"
set a c keepttl


*******************************

#14. Set Options - XX/NX

xx: is present
nx: not present

set a b
set a c
get a → "c"
flushdb

set a b xx → (nil)  if is present
get a → (nil)
set a b nx → OK  if not present
get a → "b"
set a c nx → (nil)
set a c xx → OK
get a → "c"

*******************************

#15. Exists Command

keys *
exists a → 1  existe 
exists a → 0  no existe


set user:1:session token
set user:1:session token ex 10
exists set user:1:session → 1
exists set user:1:session → 1
exists set user:1:session → 0


*******************************

#16. INCR / DECR Commands

SOLO para numéricos

set a 1
incr a → incrementa en 1 por defecto
get a → "2"
incr a
get a → "3"

set a b
get a → "b"
incr a → ERR

flushdb
incr bb → 1   si lo acepta, si no existe toma 0
get bb → "1"
incr bb

decr bb
incr prod:a:visit → 1
incr prod:b:visit
incr prod:c:visit
incr prod:c:visit
get prod:c:visit → 2 simulando los views de un producto

set a 1.02
get a
incr a → ERR not an integer

Para decimales:

incrbyfloat a .3
get a → "1.32"
incrbyfloat a -.3
get a → "1.02"
incrbyfloat a -.3
get a → "0.72"

set abc 100
incr abc → 101
incrby abc 20 → 121
incrby abc 20 → 141
incrby abc 20 → 161

*******************************

#19. Exercise - Rate Limit

set user:1:lives 3 ex 1800 → OK
ttl user:1:lives → 1790
decr user:1:lives → 2
decr user:1:lives → 1
decr user:1:lives → 0


*******************************

#20. Hash - Part 1

hset user:1 name sam age 10 city atlanta → 3 
keys * → "user:1"
get user:1 → WRONGTYPE
type user:1 → hash
hget user:1 → ERR wrong number of arguments ...
hget user:1 name → "sam"
hget user:1 age → "10"
hgetall user:1 → Para ver un listado de los campos y valores 

hset user:2 birthyear 2020 status active → 2
hgetall user:2

Recordar que no se trata de una tabla convencional, es un objeto
que no debe mantener la misma estructura de campos

*******************************

#20. Hash - Part 2

expire user:2 10 → 1
ttl user:2 → 6
keys* → "user:1"

hkeys user:1 → retorna las keys
hvals user:1 → retorna los valores
hexists user:1 status → 0 (No existe el campo)
hexists user:1 age → 1 (Si existe el campo)

Para eliminar un campo:
hdel user:1 age → 1
hgetall user:1 → aparecen todos menos el key-value de age

Para eliminar todo:
del user:1 → 1
keys * → empty array

*******************************

#22. List & Queue

La lista en Redis puede ser usada como una Queue(First in - first out)

rpush users julio ruti aaron → 3
keys * → "users"
get users → WRONGTYPE
type users → list
llen users → 3
lrange 0 -1 → Retorna los nombres, arranca en índice 0 y se pone -1 cuando no se sabe la longitud exacta 
lrange 0 1 → "julio" "ruti"

lpop users → "julio" Significa que ha sido eliminado
lrange 0 1 → "ruti" "aaron"
lpop users → "ruti"
lpop users → "aaron"
lpop users → (nil)

llen users → 0
rpush users 1 2 3 4 5 6 → 6
llen users → 6
lpop users → "1"
lpop users 2 → "2" "3"
lrange users 0 -1 → "4" "5" "6"

*******************************

#24. List As Stack

rpush users 1 2 → 2
rpush users 3 4 → 4
rpush users 5 → 5
rpush users 6 → 6 No hay necesidad de crear la lista con todos los elementos, se pueden ir agregando
llen users → 6 
lrange users 0 -1 → se muestran todos los elementos

rpop users → 6
rpop users → 5
rpop users → 4
llen users → 3
lrange users 0 -1 → "1" "2" "3"

lpush users 4 → 4
lrange users 0 -1 → "4" "1" "2" "3" El cuatro pasa a estar en la primera posición

keys * → "users"
lpop users → "4"
lpop users → "1"
lpop users → "2"
llen users → 1
lpop users → "3"
keys * → (empty array) Si no hay datos en la lista es borrada automáticamente

*******************************

#25. Redis Set

Similar a Java HashSet. Es una collección desordenada con items únicos(string)
Use cases:
- mantener el logueo de usuarios
- blacklist de ip's
- set intersection

sadd users 1 2 3 → 3 Para crear un set
sadd users 4 → 1
sadd users 5 → 1
scard users → 5 para ver la longitud del set
smembers users → Se muestran todos los elementos del set

sadd users 4.5 → 1
sadd users 10 → 1
smembers users → Se muestran todos los elementos sin un orden específico

sadd users 1 → 0 
sadd users 2 → 0
sadd users 3 → 0 No se agregan registros porque no admite duplicados

sismember users 5 → 1 Para validar si existe dentro del set
sismember users 100 → 0

srem users 100 → 0 Para eliminar un registro, como 100 no existe no afectó en nada
srem users 5 → 1
sismember users 5 → 0

spop users → "3" Para eliminar de manera random un elemento

*******************************

#26. Set Intersection & Union

sadd skill:java 1 2 3 4 → 4
sadd skill:js 2 3 4 → 3
sadd skill:aws 4 5 6 → 3

Las personas que tienen los 3 skills:
sinter skill:java skill:js skill:aws → "4"

Los que saben java y js:
sunion skill:java skill:js → "1" "2" "3" "4"

sadd candidate:criminal 4 5 6 → 3

Los que saben java y no tienen record criminal:
sdiff skill:java candidate:criminal → "1" "2" "3"

Para guardar el resultado en otro set:
Intersect para los que saben java y js:
sinterstore java-js skill:java skill:js → 3
scard java-js → 3
smembers java-js → "2" "3" "4"

*******************************

#28, 29. Sorted Set - Part 1 y 2

Es un set ordenado.
Use cases:
- Priority Queue
- top rated movie / product
- frequently visited pages

zadd products 0 books → 1 Para agregar items en el sorted set
zadd products 0 iphone 0 tv → 2
zcard products → 3 Para saber la longitud del set
zincrby products 1 books → "1" Para simular ventas de productos
zincrby products 1 iphone → "1"
zincrby products 1 iphone → "2"
zincrby products 1 tv → "1"

Para mostrar el score o el rank de los productos
zrange products 0 -1 → Para mostrar todo
1)"books"
2)"tv"
3)"iphone"

zincrby products 1 iphone → "3"
zincrby products 1 books → "2"
zrange products 0 -1 →
1)"tv"
2)"books"
3)"iphone"
Se ve que el orden es ascendente

zrange products 0 -1 withscores → Para ver el score
1)"tv"
2)"1"
3)"books"
4)"2"
5)"iphone"
6)"3"

Para ver el producto con el mayor score:
zrange products -1 -1 → "iphone"
zrange products 0 0 rev → "iphone" Otra manera de hacerlo
zrange products 0 0 rev withscores →
1)"iphone"
2)"3"

Para obtener el TOP 2 de productos:
zrange products 0 1 rev withscores →
1)"iphone"
2)"3"
3)"books"
4)"2"

Para saber el rank de un producto:
zrank products books → 1
zrank products iphone → 2

zrevrank products iphone → 0 Haciéndolo en reversa se encuentra en la primera posición

Para saber el score:
zscore products iphone → "3"
zscore products tv → "1"

Para eliminar el producto con el máximo score
zpopmax products →
1)"iphone"
2)"3"
zpopmax products →
1)"books"
2)"2"

zcard products → 1


*******************************

#32. Redis Transaction - Part 2

set user:1:balance 1 → OK
set user:2:balance 0 → OK
get user:1:balance 1 → "1"

decr user:1:balance → 0
incr user:2:balance → 1

En otra ventana:
decr user:1:balance → -1
incr user:2:balance → 2

flushdb

set user:1:balance 1 → OK
set user:2:balance 0 → OK

Para activar la transacción:
CLIENTE 1:
multi → OK
decr user:1:balance → QUEUED
incr user:2:balance → QUEUED

CLIENTE 2:
multi → OK
decr user:1:balance → QUEUED
incr user:2:balance → QUEUED

CLIENTE 1:
exec →
1) 0
2) 1

CLIENTE 2:
exec →
1) -1
2) 2

Pienso que la diferencia está que con el modo "transacción" se procesan los request en bloque

CLIENTE 1: 
set user:1:balance 1 → OK
set user:2:balance 0 → OK
watch user:1:balance user:2:balance → OK
multi → OK
decr user:1:balance → QUEUED
incr user:2:balance → QUEUED


CLIENTE 2: 
watch user:1:balance user:2:balance → OK
multi → OK
decr user:1:balance → QUEUED
incr user:2:balance → QUEUED


CLIENTE 1: 
exec →
1) 0
2) 1

CLIENTE 2:
exec → (nil) Lo que pasó fue que el watch deshabilita la TRX si la llave fue modificada por otro cliente
get user:1:balance → "0"
get user:2:balance → "1"

multi → OK
decr user:1:balance → QUEUED
incr user:2:balance → QUEUED
discard → OK sirve para hacer rollback

*******************************

#33. Saving Data On Disk

keys * → (empty array)

En el container de redis:
root@redis:/data# ls -al → total 8 No se ve data guardada

set user:1:balance 1 → OK
set user:2:balance 0 → OK
root@redis:/data# ls -al → sigue sin aparecer nada

bgsave → Background saving started 
root@redis:/data# ls -al → Aparece un archivo: dump.rdb
root@redis:/data# cat dump.rdb

Se puede ver el contenido del archivo


**********************************
SECCIÓN 4: Redisson - Crash Course
**********************************

Redisson es la librería de Java para usar Redis
Otras librerías: Jedis y Lettuce

Tener en cuenta la wiki:
https://github.com/redisson/redisson/wiki

*******************************

#40. Key Value

Lec01KeyValueTest keyValueAccessTest:
En este test se creó una key-value y se mostró el valor.

En redis-cli se muestra lo siguiente:

127.0.0.1:6379> get user:1:name
"\x04>\x05julio"

Se muestra así el valor porque no se ha realizado un encoded

*******************************

#42. Redisson Codec

Lec01KeyValueTest keyValueAccessWithCodecTest

Se agregó StringCodec.INSTANCE

Se hizo un flushdb y se probó

Ahora se muestra correctamente formateado:
127.0.0.1:6379> get user:1:name
"julio"

*******************************

#43. Bucket Expiry

Lec01KeyValueTest keyValueExpiryTest

Se agregó: bucket.set("julio", 30, TimeUnit.SECONDS);

Se hizo un flushdb y se probó

127.0.0.1:6379> keys *
1) "user:1:name"
127.0.0.1:6379> ttl user:1:name
(integer) 14
127.0.0.1:6379> ttl user:1:name
(integer) -2
127.0.0.1:6379> get user:1:name
(nil)

Lec01KeyValueTest keyValueExtendExpiryTest

Se añadió una lógica para extender el ttl y mostrarlo

Se hizo un flushdb y se probó

127.0.0.1:6379> get user:1:name
"julio"
127.0.0.1:6379> ttl user:1:name
(integer) 55
127.0.0.1:6379> ttl user:1:name
(integer) 48


*******************************

#44. Object Store

El propósito es guardar un objeto Student en Redis

Lec02BucketObjectTest keyValueObjectTest

Se puede usar cualquiera de los dos para enviar la data formateada a Redis:

-implements Serializable en la clase Student
-JsonJacksonCodec.INSTANCE en el test

Por defecto se guarda el nombre de la clase con JsonJacksonCodec, para quitarlo se agregó:
new TypedJsonJacksonCodec(Student.class)

En Intellij:
Student(name=Marshall, age=10, city=Atlanta, marks=[1, 2, 3])

En Redis:
127.0.0.1:6379> get student:1
"{\"age\":10,\"city\":\"Atlanta\",\"marks\":[1,2,3],\"name\":\"Marshall\"}"

Sería interesante saber si al consumir esta data con esas barras causa algún conflicto o cómo guardar la info sin las barras.

*******************************

#45. Number Store

El objetivo es guardar una key que incremente su valor en 1 cada segundo

Lec03NumberTest keyValueIncreaseTest

En este test destaca el uso de RAtomicLongReactive

Al probar en redis se ve que incrementa de 1 en 1 hasta llegar a 30

127.0.0.1:6379> get user:1:visit
"18"
127.0.0.1:6379> get user:1:visit
"20"
127.0.0.1:6379> get user:1:visit
"21"
127.0.0.1:6379> get user:1:visit
"25"
127.0.0.1:6379> get user:1:visit
"30"
127.0.0.1:6379> get user:1:visit
"30"

*******************************

#46. Buckets As Map

El objetivo es retornar la data de redis como un map en java.

Lec04BucketAsMap bucketAsMap

Se uso getBuckets para llamar a las keys.

Se creó la data en redis:

127.0.0.1:6379> set user:1:name aaron
OK
127.0.0.1:6379> set user:2:name ruti
OK
127.0.0.1:6379> set user:3:name julio
OK

Al ejecutar el test se obtiene:
{user:1:name=aaron, user:2:name=ruti, user:3:name=julio}

En caso de invocar a una llave que no exista redis solo la ignora y no rompe el test.


*******************************

#48. Expired Event Listener

El propósito es notificar cuando la key haya expirado

Lec05EventListenerTest expiredEventTest

Es el mismo ejemplo de Lec01KeyValueTest keyValueExtendExpiryTest pero se agregó: bucket.addListener

Las notifications están desactivadas por defecto en REDIS, para activarlas ejecutar en la consola:

config set notify-keyspace-events AKE

Reference: https://redis.io/topics/notifications#configuration

127.0.0.1:6379> config set notify-keyspace-events AKE
OK

Se ejecuta el test y luego de 11secs se notifica automáticamente la expiración:

En intellij:
julio
Expired : user:1:name


*******************************

#49. Deleted Event Listener

El propósito es notificar cuando la key haya sido borrada

Lec05EventListenerTest deletedEventListenerTest

El test es igual que expiredEventTest de la misma clase pero se quitó el tiempo de expiración de la key
También se cambió la implementación de bucket.addListener

Al ejecutar el test vemos lo siguiente en redis:

127.0.0.1:6379> keys *
1) "user:1:name"

Borramos la key:

127.0.0.1:6379> del user:1:name
(integer) 1

Se notifica automáticamente en intellij:

julio
Deleted : user:1:name


*******************************

#50. Map - Part 1

El objetivo es guardar un map en un hash de Redis:

Lec06MapTest mapTest1

Se usó getMap

Redis Hash → Redisson Map

127.0.0.1:6379> keys *
1) "user:1"
127.0.0.1:6379> get user:1
(error) WRONGTYPE Operation against a key holding the wrong kind of value

Sale error porque es un hash, se tiene que buscar así:
127.0.0.1:6379> hgetall user:1
1) "name"
2) "Julio"
3) "age"
4) "27"
5) "city"
6) "Lima"

También se puede buscar por la key:
127.0.0.1:6379> hget user:1 name
"Julio"


Lec06MapTest mapTest2

Aquí se creó un Map de java8 y se redujo el código, digamos que es otra manera de hacer el mismo test

Ejecuté el test y en redis veo lo siguiente:

127.0.0.1:6379> keys *
1) "user:2"
127.0.0.1:6379> hgetall user:2
1) "name"
2) "Ruti"
3) "city"
4) "Lima"
5) "age"
6) "30"

*******************************

#51. Map - Part 2

El objetivo es tener un Map<Integer, Student> lo cual es más cercano a un caso real.
Se usa un TypedJsonJacksonCodec para el formateo.

Lec06MapTest mapTest3

Se ejecutó el test y en redis:

127.0.0.1:6379> keys *
1) "users"
127.0.0.1:6379> hgetall users
1) "1"
2) "{\"age\":27,\"city\":\"lima\",\"marks\":[1,2,3],\"name\":\"Julio\"}"
3) "2"
4) "{\"age\":30,\"city\":\"lima\",\"marks\":[10,20,30],\"name\":\"Ruti\"}"

*******************************

#52. Map Cache

El objetivo es que se puede hacer expirar solo un "objeto" del map

Lec07MapCacheTest mapCacheTest

Se usó getMapCache. Se ejecuta el test y se valida en el mismo intellij:

Al esperar los 3 segundos aparecen los objetos:

Student(name=Julio, age=27, city=lima, marks=[1, 2, 3])
Student(name=Ruti, age=30, city=lima, marks=[10, 20, 30])

Al esperar nuevamente solo aparece el objeto no expirado:

Student(name=Ruti, age=30, city=lima, marks=[10, 20, 30])

*******************************

#53. Local Cached Map - Part 1

LocalCachedMap no es parte de ReactiveRedisson por lo que se tiene que crear un nuevo cliente

Lec08LocalCachedMapTest setupClient

Sync Strategy:
- None:       no se actualiza automáticamente
- Invalidate: elimina el objeto de memoria
- Update:     actualiza con lo que haya cambiado


Reconnect Strategy:
- Clear: Cuando se reestablece la conexión con Redis se limpia el Cache y se actualiza
- None:  Parece que no hace nada y solo mantiene la data en cache.

*******************************

#54. Local Cached Map - Part 2

Se agregan observers

Lec08LocalCachedMapTest appServer1 y appServer2.
Para las pruebas iniciales se utilizará:
SyncStrategy.UPDATE
ReconnectionStrategy.NONE

Se ejecuta appServer1 y se muestra cada segundo la data del hash:
10==>Student(name=Julio, age=27, city=lima, marks=[1, 2, 3])
11==>Student(name=Julio, age=27, city=lima, marks=[1, 2, 3])
12==>Student(name=Julio, age=27, city=lima, marks=[1, 2, 3])


Luego se ejecuta appServer2 mientras sigue en ejecución appServer1 y se actualiza el nombre:
86==>Student(name=Julio-Updated, age=27, city=lima, marks=[1, 2, 3])
87==>Student(name=Julio-Updated, age=27, city=lima, marks=[1, 2, 3])
88==>Student(name=Julio-Updated, age=27, city=lima, marks=[1, 2, 3])

Para comprobar que se usa la copia local detengo el server de redis y se ve que se sigue mostrando la data
al ejecutar appServer1.

docker-compose down

Cuando se usa el Sync Strategy NONE se ve que una vez ejeuctado appServer1 y luego appServer2
no pasa nada porque la data no se actualiza. Sin embargo en Redis si se actualizó:
127.0.0.1:6379> keys *
1) "students"
127.0.0.1:6379> hgetall students
1) "1"
2) "{\"age\":27,\"city\":\"lima\",\"marks\":[1,2,3],\"name\":\"Julio-Updated\"}"
3) "2"
4) "{\"age\":30,\"city\":\"lima\",\"marks\":[10,20,30],\"name\":\"Ruti\"}"

Al cambiar a ReconnectionStrategy.CLEAR vemos que ejecutamos appServer1 y
bajamos REDIS con docker-compose down, aparece lo sgte:

103==>Student(name=Julio, age=27, city=lima, marks=[1, 2, 3])
104==>Student(name=Julio, age=27, city=lima, marks=[1, 2, 3])

Se ejecuta: docker-compose up

Aquí podemos ver que la data en cache ha sido borrada

20:54:47.935 [parallel-1] DEBUG org.redisson.command.RedisExecutor - acquired connection for command (HGET) and params [students, PooledUnsafeDirectByteBuf(ridx: 0, widx: 1, cap: 256)] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using node 127.0.0.1/127.0.0.1:6379... RedisConnection@1158566375 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x367877b3, L:/127.0.0.1:53447 - R:127.0.0.1/127.0.0.1:6379], currentCommand=null]
20:54:47.936 [redisson-netty-5-5] DEBUG org.redisson.command.RedisExecutor - connection released for command (HGET) and params [students, PooledUnsafeDirectByteBuf(ridx: 0, widx: 1, cap: 256)] from slot NodeSource [slot=0, addr=null, redisClient=null, redirect=null, entry=null] using connection RedisConnection@1158566375 [redisClient=[addr=redis://127.0.0.1:6379], channel=[id: 0x367877b3, L:/127.0.0.1:53447 - R:127.0.0.1/127.0.0.1:6379], currentCommand=CommandData [promise=RedissonPromise [promise=ImmediateEventExecutor$ImmediatePromise@67102ecd(success)], command=(HGET), params=[students, PooledUnsafeDirectByteBuf(ridx: 0, widx: 1, cap: 256)], codec=org.redisson.codec.TypedJsonJacksonCodec]]
139==>null
140==>null
141==>null

Cabe mencionar que solo usando los comandos de docker compose se pudo hacer esta prueba, no fue igual el resultado con darle stop en docker desktop

Cuando se ejecuta appServer2 recién se puede ver que se actualiza la data:

205==>Student(name=Julio-Updated, age=27, city=lima, marks=[1, 2, 3])
206==>Student(name=Julio-Updated, age=27, city=lima, marks=[1, 2, 3])
207==>Student(name=Julio-Updated, age=27, city=lima, marks=[1, 2, 3])

Al parecer necesita la actualización de la data en Redis para que pueda leer nuevamente el origen y generar una nueva copia en cache

*******************************

#56. List

Lec09ListQueueStackTest listTest

El código comentado tiene el mismo resultado. Solo que el que no está comentado es
más eficiente porque solo hace un llamado a Redis. 

Puede que la lista no se muestre en el orden en que se espera.

En la programación tradicional se tiene que completar el list.add para continuar el loop.
En reactive programming se están creando 10 publishers para enviar a redis.

El código que quedó sin comentarios es para hacer una sola invocación a redis y no 10

Para validar los datos en redis:

lrange number-input 0 -1

*******************************

#57. Queue & Stack

Lec09ListQueueStackTest queueTest

La lista debe quedar creada con el test anterior.
Se usó queue.poll() para borrar elementos y resultó así en redis:

127.0.0.1:6379> lrange number-input 0 -1
1) "5"
2) "6"
3) "7"
4) "8"
5) "9"
6) "10"


Lec09ListQueueStackTest stackTest

En el ejemplo de Stack que es Deque se eliminaron:

10
9
8
7

Se usó deque.pollLast()

127.0.0.1:6379> lrange number-input 0 -1
1) "5"
2) "6"


*******************************

#58. Message Queue

Lec10MessageQueueTest consumer1, consumer2 y producer

Se utiliza Redis como un messagequeue. Se ejecuta consumer1 y se queda esperando
luego el producer y se ve que consumer1 lee la data de redis, luego se corre consumer2 
y ambos consumers toman la data sin repetirla(no duplicate processing).


Por lo que veo solo se usa redis como msgqueue pero no se guarda un objeto

*******************************

#59. HyperLogLog

Lec11HyperLogLogTest count

Trabaja con probabilidades.

*******************************

#60. Pub Sub

Publisher -> Subscriber
Si un mensaje es publicado los subscribers lo reciben

Lec12PubSubTest subscriber1, subscriber2

Para replicar este ejemplo usar subscriber1 y clonarlo cambiando de nombre al método.

Ejecutar los test individualmente y dejar esperando.
En redis:
127.0.0.1:6379> publish slack-room hi
(integer) 2
127.0.0.1:6379> publish slack-room "hello guys how are u?"
Se usan comillas cuando el texto tiene espacio

En las consolas de intellij se ve que nuestros subscribers leyeron
la info correctamente.

Se terminó una consola de test y se agregó nuevo mensaje el cual es
leído bien por el subscriber activo. Cuando iniciamos el otro test no
aparece ningún mensaje. Solo funciona con subscribers activos.

*******************************

#61. Pub Sub Pattern

Para que un subscriber pueda escuchar de diferentes publishers

Lec12PubSubTest subscriber1, subscriber2

127.0.0.1:6379> publish slack-room1 hello
(integer) 2
127.0.0.1:6379> publish slack-room2 hello2
(integer) 1

Los mensajes se muestran en el subscriber2 y en el 1 solo los de slack-room1

*******************************

#62. Batch / Redis Pipeline

Para procesamiento grande

Lec13BatchTest batchTest
Se agregaron 500K numeros a una lista y a un set

Se realizó en 9secs
127.0.0.1:6379> scard numbers-set
(integer) 500000

Hacer un flushdb

Se hizo el regularTest para ver cuánto demora sin batch y es muy notable la diferencia.
El test se tardó 1min 40secs

*******************************

#63. Transaction

Lec14Transaction nonTransactionTest

A pesar del error de la división entre cero se ve que igual se hace la transferencia:
[50,50]

Lec14Transaction transactionTest
Con el Transaction tengo la posibilidad de hacer commit y rollback en caso de error

[100,0]

Comentar la línea del error para ver el caso de éxito

*******************************

#65. Sorted Set

Lec15SortedSetTest sortedTest

sortedSet.addScore("julio", 12.25);
Esta línea valida automáticamente si "julio" existe y de ser así
reemplaza el value actual, sino lo crea.

Al ejecutar el test se ve que el registro de "aaron" aumenta mientras que
"ruti" no porque solo está usando add()

21.0 : aaron
23.26 : ruti

*******************************

67. ASSIGNMENT SOLUTION - Priority Queue

Lec16PriorityQueueTest(buscar en la carpeta test/assignment)

Primero ejecutar el producer y luego el consumer
Se ve que muestra los items en el orden esperado(PRIME -> STD -> GUEST)
Se generan varios registros en el nuevo test y se ve que una vez terminado
el producer, el consumer ordena los valores correctamente.

**********************************
SECCIÓN 5: Spring Webflux Caching 
**********************************

Crear el proyecto redis-spring con las dependencias:
- Spring Data Reactive Redis
- Spring Reactive Web
- Lombok

Usar una versión estable de spring boot como 2.7.9 para evitar
errores de compilación.

Agregar con File -> New -> Module from existing sources

Si no es para config local:

spring.redis.host=10.11.12.13
spring.redis.port=6379

*******************************

72. Spring Data Redis vs Redisson

En RedisSpringApplicationTests se crearon los métodos:

@RepeatedTest(3)
springDataRedisTest

Se valida cuánto tiempo demora la generación de items en las 3 repeticiones
29078
29632
29058

Comentar la dependencia de redis-reactive y agregar:
<dependency>
  <groupId>org.redisson</groupId>
  <artifactId>redisson-spring-boot-starter</artifactId>
  <version>3.16.0</version>
</dependency>

flushdb y ejecutar otra vez el test. El resultado es casi igual, de hecho en mi pc
demora más:
39076
34342
33939

Se crea el método redissonTest. Al probar demora más, sin embargo en el video demora mucho menos:
45107
42189
43513

La lección consiste en que spring data reactive tiene problemas de performance y es mejor usar redisson.

*******************************

73. Cache Aside Pattern
74. Fib Service

Se creó el package /fib
Al invocar al servicio: http://localhost:8080/fib/10
Me retorna el número que corresponde pero cuando envío /45
o un número mayor se toma demasiado tiempo en responder.


*******************************

75. @Cacheable - Part 1

Skip the method execution if the key is present.
Do the method execution only if the key is not present and store the result.

RedissonCacheConfig class in the fib/config/ package

@Cacheable("math:fib") in the method getFib() of the FibService class
This create a hash in Redis

@EnableCaching in the main class : RedisSpringApplication

Al ejecutar se puede ver que guarda en cache la información y no la vuelve a "pedir" o "procesar"
Calculating fib for 2
Calculating fib for 5
Calculating fib for 45

En redis:
127.0.0.1:6379> keys *
1) "math:fib"
127.0.0.1:6379> type math:fib
hash
127.0.0.1:6379> hgetall math:fib
1) "\x04K\x00\x00\x00\x02"
2) "\x04K\x00\x00\x00\x01"
3) "\x04K\x00\x00\x00\x05"
4) "\x04K\x00\x00\x00\x05"
5) "\x04K\x00\x00\x00-"
6) "\x04KC\xa5?\x82"

*******************************

76. @Cacheable - Part 2

String name was added in service and controller

http://localhost:8080/fib/45/aaron

if the name change then the program take time to calculate, but this is not necessary
Calculating fib for 45, name: julio
Calculating fib for 45, name: aaron

To fix this, add in getFib of FibService:
@Cacheable(value = "math:fib", key = "#index")
index was added because is the field that need to be calculated

Do a flush db and test.
Calculating fib for 45, name: julio
This time when I change the name it doesn't take time or do an additional process

*******************************

77. Cache Evict

Do the method execution always and evict the corresponding cache
Evict happens after method execution

it is necessary to have a strategy for cache evict
this annotation is util when you use POST/PUT/PATCH/DELETE

i commented the methods that include string name for this test

Calculating fib for 45
Calculating fib for 46

When I invoke:
http://localhost:8080/fib/46
Then:
clearing hash key
Calculating fib for 46

When I use Cache Evict the hash key is deleted

*******************************

78. Scheduled Cache Evict

I added the method:

Every ten seconds it will delete the cache

@Scheduled(fixedRate = 10_000)
@CacheEvict(value = "math:fib", allEntries = true)
public void clearCache() {
    System.out.println("clearing all math:fib keys");
}

And I added this annotation in the main class:
@EnableScheduling

*******************************

79. @CachePut - Part 1

Do the method execution always and update the corresponding cache
Is like a hibrid between @Cacheable and @CacheEvict

See the /weather package

http://localhost:8080/weather/3

In this example of weather application we use the data of redis not of the serviceClient

*******************************

81. Cache Annotation Limitations

- No TTL support
- Not a lot of flexibility
- Does not work with publisher types!!!
  (Not support reactive classes like Mono<Product>)

*******************************

83. City Service - Client
84. City Service

In a console execute the "external service" with this:
java -jar city-api.jar

Add in application.properties:
city.service.url=http://localhost:3030/open-city-api/

http://localhost:3030/open-city-api/10001
http://localhost:3030/open-city-api/30005

{
"zip": "10001",
"lat": 40.75065,
"lng": -73.99718,
"city": "New York",
"stateId": "NY",
"stateName": "New York",
"population": 24117,
"density": 15153.7,
"temperature": 92
}

The files are in /city folder

In CityService:
put replace while fastput just "put"

85. City Service - Controller

do a flushdb and run the application

Invoke:
http://localhost:8080/city/10001

{
"zip": "10001",
"city": "New York",
"stateName": "New York",
"temperature": 64
}

In redis:
127.0.0.1:6379> keys *
1) "city"
2) "weather"
127.0.0.1:6379> type city
hash
127.0.0.1:6379> hgetall city
1) "\"10001\""
2) "{\"city\":\"New York\",\"stateName\":\"New York\",\"temperature\":64,\"zip\":\"10001\"}"

*******************************

87. Setting TTL

the modifications are in the CityService with comments like //TTL

it remove all the entries from redis

127.0.0.1:6379> keys *
1) "redisson__execute_task_once_latch:{city}"

*******************************

89. ASSIGNMENT

I commented the previous example to do this.

With this changes in CityService and CityClient it is possible to get any zipcode 
in a fast way.

